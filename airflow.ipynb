{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import boto3\n",
    "import sqlite3\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "from feast import FeatureStore\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 1. Data Ingestion\n",
    "def fetch_transaction_data():\n",
    "    return pd.read_csv(\"transactions.csv\")\n",
    "\n",
    "def fetch_customer_data():\n",
    "    api_url = \"https://api.example.com/customers\"\n",
    "    response = requests.get(api_url)\n",
    "    return response.json()\n",
    "\n",
    "transactions = fetch_transaction_data()\n",
    "customers = fetch_customer_data()\n",
    "\n",
    "# Save ingested data\n",
    "transactions.to_csv(\"raw_transactions.csv\", index=False)\n",
    "with open(\"raw_customer_data.json\", \"w\") as f:\n",
    "    f.write(str(customers))\n",
    "\n",
    "print(\"Data ingestion completed successfully!\")\n",
    "\n",
    "# 2. Raw Data Storage\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"customer-churn-data\"\n",
    "\n",
    "# Upload files\n",
    "s3.upload_file(\"raw_transactions.csv\", bucket_name, \"raw/transactions.csv\")\n",
    "s3.upload_file(\"raw_customer_data.json\", bucket_name, \"raw/customer_data.json\")\n",
    "\n",
    "print(\"Files uploaded successfully to S3!\")\n",
    "\n",
    "# 3. Data Validation\n",
    "df = pd.read_csv(\"raw_transactions.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Validate column data types\n",
    "expected_types = {'customer_id': int, 'transaction_amount': float, 'transaction_date': str}\n",
    "for col, expected_type in expected_types.items():\n",
    "    if df[col].dtype != expected_type:\n",
    "        print(f\"Column {col} has incorrect data type\")\n",
    "\n",
    "print(\"Data validation completed!\")\n",
    "\n",
    "# 4. Data Preparation\n",
    "df = pd.read_csv(\"raw_transactions.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Convert date column to datetime\n",
    "df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"])\n",
    "\n",
    "# Feature Engineering: Total spend per customer\n",
    "customer_spend = df.groupby(\"customer_id\")[\"transaction_amount\"].sum().reset_index()\n",
    "customer_spend.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"Data preparation completed!\")\n",
    "\n",
    "# 5. Data Transformation and Storage\n",
    "# SQL Schema for Storing Transformed Data\n",
    "conn = sqlite3.connect(\"customer_churn.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS transformed_data (\n",
    "    customer_id INT PRIMARY KEY,\n",
    "    total_spend FLOAT,\n",
    "    last_transaction_date DATE\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert Transformed Data\n",
    "cursor.execute(\"INSERT INTO transformed_data (customer_id, total_spend, last_transaction_date) VALUES (?, ?, ?)\",\n",
    "               (101, 250.50, \"2023-12-01\"))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Data inserted successfully!\")\n",
    "\n",
    "# 6. Feature Store\n",
    "# Using Feast for Feature Management\n",
    "store = FeatureStore(repo_path=\"feature_repo\")\n",
    "\n",
    "# Retrieve features for model training\n",
    "customer_features = store.get_online_features(\n",
    "    entity_rows=[{\"customer_id\": 101}],\n",
    "    features=[\"customer.total_spend\", \"customer.last_transaction_date\"]\n",
    ").to_dict()\n",
    "\n",
    "print(customer_features)\n",
    "\n",
    "# 7. Data Versioning\n",
    "# Using DVC for Data Versioning\n",
    "# Run these commands in a terminal or Jupyter Notebook cell\n",
    "# !dvc init\n",
    "# !dvc add cleaned_data.csv\n",
    "# !git add cleaned_data.csv.dvc\n",
    "# !git commit -m \"Added versioned cleaned data\"\n",
    "\n",
    "# 8. Model Building\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Assume a churn label column exists\n",
    "X = df[[\"total_spend\"]]\n",
    "y = df[\"churn_label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "with open(\"churn_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# 9. Pipeline Orchestration\n",
    "# Automating with Apache Airflow\n",
    "def ingest_data():\n",
    "    print(\"Ingesting Data...\")\n",
    "\n",
    "dag = DAG(\"customer_churn_pipeline\", start_date=datetime(2023, 1, 1), schedule_interval=\"@daily\")\n",
    "\n",
    "ingest_task = PythonOperator(\n",
    "    task_id=\"ingest_data\",\n",
    "    python_callable=ingest_data,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "ingest_task\n",
    "\n",
    "# 10. Model Deployment\n",
    "# Deploying Model using Flask API\n",
    "app = Flask(__name__)\n",
    "model = pickle.load(open(\"churn_model.pkl\", \"rb\"))\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    prediction = model.predict([[data[\"total_spend\"]]])\n",
    "    return jsonify({\"churn_prediction\": int(prediction[0])})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
